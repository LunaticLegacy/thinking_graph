[llm]
backend = "local_api"

[llm.remote_api]
api_key = ""
base_url = "https://api.openai.com/v1"
model = "gpt-4o-mini"

[llm.local_api]
api_key = ""
base_url = "http://127.0.0.1:11434/v1"
model = "qwen2.5:7b"

[llm.local_runtime]
model = "qwen2.5-7b-instruct"
model_dir = "models"
npu_device = "NPU"
require_npu = true
onnx_provider = ""
